{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sortedcontainers import SortedList, SortedDict, SortedSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data and Create Relevant Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kaggle_visible_evaluation_triplets.txt', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = pd.read_csv('kaggle_songs.txt', header=None, sep=' ')\n",
    "song_to_kaggle = dict()\n",
    "for idx, row in kaggle.iterrows():\n",
    "    song_to_kaggle[row[0]] = row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating_list = dict()\n",
    "user_rating_list = defaultdict(lambda:list(), user_rating_list)\n",
    "\n",
    "song_rating_list = dict()\n",
    "song_rating_list = defaultdict(lambda:list(), song_rating_list)\n",
    "\n",
    "id_to_user = dict()\n",
    "user_to_id = dict()\n",
    "id_to_song = dict()\n",
    "song_to_id = dict()\n",
    "user_idx = -1\n",
    "song_idx = -1\n",
    "last_user = 0\n",
    "\n",
    "total = 0\n",
    "ratings = 0\n",
    "\n",
    "for i in range(len(data.iloc[:,0])):\n",
    "    \n",
    "    if data.iloc[i,0] != last_user:\n",
    "        user_idx += 1\n",
    "        id_to_user[user_idx] = data.iloc[i,0]\n",
    "        user_to_id[data.iloc[i,0]] = user_idx\n",
    "        last_user = data.iloc[i,0]\n",
    "\n",
    "    user_rating_list[user_idx].append((song_idx, data.iloc[i,2]))\n",
    "        \n",
    "    if data.iloc[i,1] in song_to_id:\n",
    "        song_rating_list[song_to_id[data.iloc[i,1]]].append((user_idx, data.iloc[i,2]))\n",
    "    else:\n",
    "        song_idx += 1\n",
    "        id_to_song[song_idx] = data.iloc[i,1]\n",
    "        song_to_id[data.iloc[i,1]] = song_idx\n",
    "        song_rating_list[song_idx].append((user_idx, data.iloc[i,2]))\n",
    "    \n",
    "    total += data.iloc[i,2]\n",
    "    ratings += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 90 # epochs\n",
    "user_ct = len(user_rating_list)\n",
    "song_ct = len(song_rating_list)\n",
    "K = 30 # latent factors (cross validate)\n",
    "mu = total / ratings # average of all known ratings\n",
    "reg = 9 # regularization (cross validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "U = np.random.randn(user_ct, K) / K\n",
    "S = np.random.randn(K, song_ct) / K\n",
    "U_bias = np.zeros(user_ct)\n",
    "S_bias = np.zeros(song_ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_ct, song_ct, user_rating_list, song_rating_list, K, U_bias, S_bias, mu, S, U, T):\n",
    "    timect = 0\n",
    "    for t in range(T):\n",
    "        update_u_bias(user_ct, user_rating_list, U, S, S_bias, mu, U_bias)\n",
    "        update_u(user_ct, user_rating_list, K, U_bias, S_bias, mu, S, U)\n",
    "        update_s_bias(song_ct, song_rating_list, U, S, U_bias, mu, S_bias)\n",
    "        update_s(song_ct, song_rating_list, K, U, U_bias, S_bias, mu, S)\n",
    "        \n",
    "        timect += 1\n",
    "        print('|{0:50s}| {1:3f}%\\r'.format('='*round((timect/T)*50), (timect/T) * 100), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_u(user_ct, user_rating_list, K, U_bias, S_bias, mu, S, U):\n",
    "    for i in range(user_ct):\n",
    "        if i in user_rating_list:\n",
    "            matrix = np.zeros((K, K)) + reg*np.eye(K)\n",
    "            vector = np.zeros(K)\n",
    "            for j, r in user_rating_list[i]:\n",
    "                matrix += np.outer(S[:,j], S[:,j])\n",
    "                vector += (r - U_bias[i] - S_bias[j] - mu)*S[:,j]\n",
    "            U[i,:] = np.linalg.solve(matrix, vector)\n",
    "    \n",
    "def update_s(song_ct, song_rating_list, K, U, U_bias, S_bias, mu, S):\n",
    "    for j in range(song_ct):\n",
    "        if j in song_rating_list:\n",
    "            matrix = np.zeros((K, K)) + reg*np.eye(K)\n",
    "            vector = np.zeros(K)\n",
    "            for i, r in song_rating_list[j]:\n",
    "                matrix += np.outer(U[i,:], U[i,:])\n",
    "                vector += (r - U_bias[i] - S_bias[j] - mu)*U[i,:]\n",
    "            S[:,j] = np.linalg.solve(matrix, vector)\n",
    "    \n",
    "def update_u_bias(user_ct, user_rating_list, U, S, S_bias, mu, U_bias):\n",
    "    for i in range(user_ct):\n",
    "        if i in user_rating_list:\n",
    "            accum = 0\n",
    "            for j, r in user_rating_list[i]:\n",
    "                accum += (r - U[i,:].dot(S[:,j]) - S_bias[j] - mu)\n",
    "            U_bias[i] = accum / (len(user_rating_list[i]) + reg)\n",
    "    \n",
    "def update_s_bias(song_ct, song_rating_list, U, S, U_bias, mu, S_bias):\n",
    "    for j in range(song_ct):\n",
    "        if j in song_rating_list:\n",
    "            accum = 0\n",
    "            for i, r in song_rating_list[j]:\n",
    "                accum += (r - U[i,:].dot(S[:,j]) - U_bias[i] - mu)\n",
    "            S_bias[j] = accum / (len(song_rating_list[j]) + reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|==================================================| 100.000000%\r"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    recommend(user_ct, song_ct, user_rating_list, song_rating_list, K, U_bias, S_bias, mu, S, U, T)\n",
    "except KeyboardInterrupt:\n",
    "    file_Name1 = \"SaveU\"\n",
    "    file_Name2 = \"SaveS\"\n",
    "    file_Name3 = \"SaveU_bias\"\n",
    "    file_Name4 = \"SaveS_bias\"\n",
    "    \n",
    "    fileObject1 = open(file_Name1,'wb')\n",
    "    fileObject2 = open(file_Name2,'wb')\n",
    "    fileObject3 = open(file_Name3,'wb')\n",
    "    fileObject4 = open(file_Name4,'wb')\n",
    "\n",
    "    pickle.dump(U,fileObject1)\n",
    "    pickle.dump(S,fileObject2)\n",
    "    pickle.dump(U_bias,fileObject3)\n",
    "    pickle.dump(S_bias,fileObject4)\n",
    "\n",
    "    fileObject1.close()\n",
    "    fileObject2.close()\n",
    "    fileObject3.close()\n",
    "    fileObject4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export/Load Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_Name1 = \"SaveU\"\n",
    "# file_Name2 = \"SaveS\"\n",
    "# file_Name3 = \"SaveU_bias\"\n",
    "# file_Name4 = \"SaveS_bias\"\n",
    "\n",
    "# fileObject1 = open(file_Name1,'wb')\n",
    "# fileObject2 = open(file_Name2,'wb')\n",
    "# fileObject3 = open(file_Name3,'wb')\n",
    "# fileObject4 = open(file_Name4,'wb')\n",
    "\n",
    "# pickle.dump(U,fileObject1)\n",
    "# pickle.dump(S,fileObject2)\n",
    "# pickle.dump(U_bias,fileObject3)\n",
    "# pickle.dump(S_bias,fileObject4)\n",
    "\n",
    "# fileObject1.close()\n",
    "# fileObject2.close()\n",
    "# fileObject3.close()\n",
    "# fileObject4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileObject1 = open(\"SaveU\",'rb')\n",
    "# fileObject2 = open(\"SaveS\",'rb')\n",
    "# fileObject3 = open(\"SaveU_bias\",'rb')\n",
    "# fileObject4 = open(\"SaveS_bias\",'rb')\n",
    "\n",
    "# U = pickle.load(fileObject1)\n",
    "# S = pickle.load(fileObject2)\n",
    "# U_bias = pickle.load(fileObject3)\n",
    "# S_bias = pickle.load(fileObject4)\n",
    "\n",
    "# fileObject1.close()\n",
    "# fileObject2.close()\n",
    "# fileObject3.close()\n",
    "# fileObject4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_users_temp = np.asarray(pd.read_csv('year1_valid_triplets_hidden.txt', header=None, sep='\\t')).T[0]\n",
    "canonical_users = []\n",
    "last_user = 0\n",
    "\n",
    "for user in canonical_users_temp:\n",
    "    if user != last_user:\n",
    "        canonical_users.append(user)\n",
    "        last_user = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|==================================================| 100.000000%\r"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "f = open('submission.txt', 'w')\n",
    "timect = 0\n",
    "\n",
    "for user in canonical_users:\n",
    "    songs_to_recommend = []\n",
    "    song_ranking = dict()\n",
    "    user_id = user_to_id[user]\n",
    "    \n",
    "    for song_id in song_rating_list:\n",
    "        song_ranking[song_id] = np.matmul(U[user_id],S[:,song_id])\n",
    "    \n",
    "    sorted_ranking = sorted(song_ranking.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "    top500 = sorted_ranking[:500]\n",
    "    dt=np.dtype('int,float')\n",
    "    top500 = np.array(top500,dtype=dt)['f0']\n",
    "    top = []\n",
    "    for song_id in top500:\n",
    "        song = id_to_song[song_id]\n",
    "        track = song_to_kaggle[song]\n",
    "        top.append(str(track))\n",
    "    \n",
    "    # Write line for that user\n",
    "    f.write(' '.join(top) + '\\n')\n",
    "    \n",
    "    timect += 1\n",
    "    if timect % 10 == 0:\n",
    "        print('|{0:50s}| {1:3f}%\\r'.format('='*round((timect/len(canonical_users))*50), (timect/len(canonical_users)) * 100), end='')\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
